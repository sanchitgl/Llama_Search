{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"msmarco_tiny\"\n",
    "\n",
    "dataset_path = \"../datasets/msmarco_tiny/\"\n",
    "corpus_file = \"tiny_collection.json\"\n",
    "queries_file = \"topics.dl20.txt\"\n",
    "qrels_test_file = \"qrels.dl20-passage.txt\"\n",
    "training_set = \"msmarco_triples.train.tiny.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "# data_path = f\"../datasets/{dataset}\"\n",
    "# corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus into memory ...\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import pytrec_eval\n",
    "import json\n",
    "\n",
    "def load_queries(path):\n",
    "    \"\"\"Returns a dictionary whose keys are query ids and values are query texts.\"\"\"\n",
    "    queries = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query_id, query_text = line.strip().split('\\t')\n",
    "            queries[query_id] = query_text\n",
    "    return queries\n",
    "\n",
    "\n",
    "def load_corpus_tsv(path):\n",
    "    \"\"\"Returns a dictionary whose keys are passage ids and values are passage texts.\"\"\"\n",
    "    corpus = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            passage_id, passage_text = line.strip().split('\\t')\n",
    "            corpus[passage_id] = {'text': passage_text}\n",
    "    return corpus\n",
    "\n",
    "def load_corpus_json(path):\n",
    "    with open(path, 'r') as corpus_f:\n",
    "        corpus_json = json.load(corpus_f)\n",
    "    return corpus_json\n",
    "\n",
    "\n",
    "def load_qrels(path):\n",
    "    with open(path, 'r') as f_qrel:\n",
    "        qrels = pytrec_eval.parse_qrel(f_qrel)\n",
    "\n",
    "    return qrels\n",
    "\n",
    "\n",
    "def load_triplets(path):\n",
    "    triplets = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query, positive_passage, negative_passage = line.strip().split('\\t')\n",
    "            triplets.append([query, positive_passage, negative_passage])\n",
    "    return triplets\n",
    "\n",
    "# Don't need to load triplet for training bm25\n",
    "# triplets = load_triplets('msmarco_triples.train.tiny.tsv')\n",
    "\n",
    "qrels = load_qrels(f\"{dataset_path}{qrels_test_file}\")\n",
    "queries = load_queries(f\"{dataset_path}{queries_file}\")\n",
    "print(\"Loading corpus into memory ...\")\n",
    "# corpus = load_corpus(f\"{dataset_path}{corpus_file}\")\n",
    "corpus = load_corpus_json(f\"{dataset_path}{corpus_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510585"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"ab\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"JS2mz8c3RdOol8iLxCkFHA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"7.9.2\",\n",
      "    \"build_flavor\" : \"oss\",\n",
      "    \"build_type\" : \"tar\",\n",
      "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
      "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"8.6.2\",\n",
      "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -sX GET \"localhost:9200/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/510585 [00:00<?, ?docs/s]               \n",
      "que: 100%|██████████| 1/1 [00:08<00:00,  8.74s/it]\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "#### Provide parameters for elastic-search\n",
    "hostname = \"localhost\"\n",
    "index_name = \"msmarco_tiny\"\n",
    "initialize = True # True, will delete existing index with same name and reindex all documents\n",
    "\n",
    "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
    "retriever = EvaluateRetrieval(model)\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.56481,\n",
       "  'NDCG@3': 0.52567,\n",
       "  'NDCG@5': 0.51208,\n",
       "  'NDCG@10': 0.48734,\n",
       "  'NDCG@100': 0.54852,\n",
       "  'NDCG@1000': 0.67747},\n",
       " {'MAP@1': 0.02848,\n",
       "  'MAP@3': 0.06355,\n",
       "  'MAP@5': 0.09368,\n",
       "  'MAP@10': 0.13795,\n",
       "  'MAP@100': 0.34717,\n",
       "  'MAP@1000': 0.4222},\n",
       " {'Recall@1': 0.02848,\n",
       "  'Recall@3': 0.06741,\n",
       "  'Recall@5': 0.10321,\n",
       "  'Recall@10': 0.16663,\n",
       "  'Recall@100': 0.57261,\n",
       "  'Recall@1000': 0.89188},\n",
       " {'P@1': 0.7037,\n",
       "  'P@3': 0.65432,\n",
       "  'P@5': 0.62593,\n",
       "  'P@10': 0.54074,\n",
       "  'P@100': 0.30093,\n",
       "  'P@1000': 0.0553})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "ndcg, _map, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
