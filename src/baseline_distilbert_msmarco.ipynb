{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"msmarco_tiny\"\n",
    "\n",
    "dataset_path = \"../beir/datasets/msmarco_tiny/\"\n",
    "corpus_file = \"tiny_collection.json\"\n",
    "queries_file = \"topics.dl20.txt\"\n",
    "qrels_test_file = \"qrels.dl20-passage.txt\"\n",
    "training_set = \"msmarco_triples.train.tiny.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "model_name = \"distilbert-base-uncased\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import losses, models, SentenceTransformer\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.train import TrainRetriever\n",
    "import pathlib, os, tqdm\n",
    "import logging\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triplets(path):\n",
    "    triplets = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query, positive_passage, negative_passage = line.strip().split('\\t')\n",
    "            triplets.append([query, positive_passage, negative_passage])\n",
    "    return triplets\n",
    "\n",
    "triplets = load_triplets(f\"{dataset_path}{training_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:23:43 - Use pytorch device_name: cuda\n"
     ]
    }
   ],
   "source": [
    "#### Provide any sentence-transformers or HF model\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Input Examples:   0%|          | 0/917 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Input Examples: 100%|██████████| 917/917 [00:00<00:00, 41252.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:25:34 - Loaded 11000 training pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = TrainRetriever(model=model, batch_size=12)\n",
    "\n",
    "#### Prepare triplets samples\n",
    "train_samples = retriever.load_train_triplets(triplets=triplets)\n",
    "train_dataloader = retriever.prepare_train_triplets(train_samples)\n",
    "\n",
    "#### Training SBERT with cosine-product\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model)\n",
    "\n",
    "ir_evaluator = retriever.load_dummy_evaluator()\n",
    "\n",
    "#### Provide model save path\n",
    "model_save_path = os.path.join(\"../\", \"output\", \"{}-v1-{}\".format(model_name, dataset))\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "#### Configure Train params\n",
    "num_epochs = 10\n",
    "evaluation_steps = 5000\n",
    "warmup_steps = int(len(train_samples) * num_epochs / retriever.batch_size * 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:25:41 - Starting to Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/.pyenv/versions/3.11.6/lib/python3.11/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9160' max='9160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9160/9160 23:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717039698.707815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1832</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717039844.021595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2748</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717039987.830306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3664</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040130.348752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040276.147916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040343.546629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5496</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040424.160553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6412</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040563.502927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7328</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040701.996164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8244</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040838.653505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9160</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717040976.750572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:28:18 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:30:44 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:33:07 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:35:30 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:37:56 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:39:03 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:40:24 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:42:43 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:45:02 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:47:18 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:49:36 - Save model to ../output/distilbert-base-uncased-v1-msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "retriever.fit(train_objectives=[(train_dataloader, train_loss)], \n",
    "                evaluator=ir_evaluator, \n",
    "                epochs=num_epochs,\n",
    "                output_path=model_save_path,\n",
    "                warmup_steps=warmup_steps,\n",
    "                evaluation_steps=evaluation_steps,\n",
    "                use_amp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test set\n",
    "# corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")\n",
    "\n",
    "import collections\n",
    "import pytrec_eval\n",
    "import json\n",
    "\n",
    "def load_queries(path):\n",
    "    \"\"\"Returns a dictionary whose keys are query ids and values are query texts.\"\"\"\n",
    "    queries = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query_id, query_text = line.strip().split('\\t')\n",
    "            queries[query_id] = query_text\n",
    "    return queries\n",
    "\n",
    "\n",
    "def load_qrels(path):\n",
    "    with open(path, 'r') as f_qrel:\n",
    "        qrels = pytrec_eval.parse_qrel(f_qrel)\n",
    "\n",
    "    return qrels\n",
    "\n",
    "\n",
    "def load_corpus_json(path):\n",
    "    with open(path, 'r') as corpus_f:\n",
    "        corpus_json = json.load(corpus_f)\n",
    "    return corpus_json\n",
    "\n",
    "\n",
    "qrels = load_qrels(f\"{dataset_path}{qrels_test_file}\")\n",
    "queries = load_queries(f\"{dataset_path}{queries_file}\")\n",
    "corpus = load_corpus_json(f\"{dataset_path}{corpus_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:30:11 - Use pytorch device_name: cuda\n",
      "2024-06-02 20:30:11 - Load pretrained SentenceTransformer: ../output/distilbert-base-uncased-v1-msmarco_tiny\n",
      "2024-06-02 20:30:12 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:30:12 - Sorting Corpus by document length (Longest first)...\n",
      "2024-06-02 20:30:13 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-06-02 20:30:13 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-06-02 20:30:13 - Encoding Batch 1/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [01:03<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:31:17 - Encoding Batch 2/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:32:10 - Encoding Batch 3/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:45<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:32:57 - Encoding Batch 4/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:37<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:33:35 - Encoding Batch 5/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:33<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:34:09 - Encoding Batch 6/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:31<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:34:41 - Encoding Batch 7/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:30<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:35:12 - Encoding Batch 8/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:28<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:35:41 - Encoding Batch 9/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:26<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:36:08 - Encoding Batch 10/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:23<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:36:32 - Encoding Batch 11/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 83/83 [00:03<00:00, 21.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "## Load retriever from saved model\n",
    "model_save_path = os.path.join(\"../\", \"output\", \"{}-v1-{}\".format(model_name, dataset))\n",
    "model = DRES(models.SentenceBERT(model_save_path), batch_size=128)\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{dataset_path}{dataset}_distilBertR_scores.pickle\", 'wb') as f:\n",
    "    pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:55:55 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-06-02 20:55:55 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2024-06-02 20:55:55 - \n",
      "\n",
      "2024-06-02 20:55:55 - NDCG@1: 0.6265\n",
      "2024-06-02 20:55:55 - NDCG@3: 0.5957\n",
      "2024-06-02 20:55:55 - NDCG@5: 0.5976\n",
      "2024-06-02 20:55:55 - NDCG@10: 0.5535\n",
      "2024-06-02 20:55:55 - NDCG@100: 0.5523\n",
      "2024-06-02 20:55:55 - NDCG@1000: 0.6391\n",
      "2024-06-02 20:55:55 - \n",
      "\n",
      "2024-06-02 20:55:55 - MAP@1: 0.0367\n",
      "2024-06-02 20:55:55 - MAP@3: 0.0747\n",
      "2024-06-02 20:55:55 - MAP@5: 0.1051\n",
      "2024-06-02 20:55:55 - MAP@10: 0.1539\n",
      "2024-06-02 20:55:55 - MAP@100: 0.3390\n",
      "2024-06-02 20:55:55 - MAP@1000: 0.3811\n",
      "2024-06-02 20:55:55 - \n",
      "\n",
      "2024-06-02 20:55:55 - Recall@1: 0.0367\n",
      "2024-06-02 20:55:55 - Recall@3: 0.0780\n",
      "2024-06-02 20:55:55 - Recall@5: 0.1130\n",
      "2024-06-02 20:55:55 - Recall@10: 0.1819\n",
      "2024-06-02 20:55:55 - Recall@100: 0.5381\n",
      "2024-06-02 20:55:55 - Recall@1000: 0.7627\n",
      "2024-06-02 20:55:55 - \n",
      "\n",
      "2024-06-02 20:55:55 - P@1: 0.7963\n",
      "2024-06-02 20:55:55 - P@3: 0.7531\n",
      "2024-06-02 20:55:55 - P@5: 0.7222\n",
      "2024-06-02 20:55:55 - P@10: 0.6056\n",
      "2024-06-02 20:55:55 - P@100: 0.2783\n",
      "2024-06-02 20:55:55 - P@1000: 0.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.62654,\n",
       "  'NDCG@3': 0.59571,\n",
       "  'NDCG@5': 0.59759,\n",
       "  'NDCG@10': 0.55349,\n",
       "  'NDCG@100': 0.55234,\n",
       "  'NDCG@1000': 0.63912},\n",
       " {'MAP@1': 0.03666,\n",
       "  'MAP@3': 0.07473,\n",
       "  'MAP@5': 0.10514,\n",
       "  'MAP@10': 0.15388,\n",
       "  'MAP@100': 0.33904,\n",
       "  'MAP@1000': 0.38106},\n",
       " {'Recall@1': 0.03666,\n",
       "  'Recall@3': 0.078,\n",
       "  'Recall@5': 0.11304,\n",
       "  'Recall@10': 0.18187,\n",
       "  'Recall@100': 0.53806,\n",
       "  'Recall@1000': 0.76265},\n",
       " {'P@1': 0.7963,\n",
       "  'P@3': 0.75309,\n",
       "  'P@5': 0.72222,\n",
       "  'P@10': 0.60556,\n",
       "  'P@100': 0.27833,\n",
       "  'P@1000': 0.04596})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "ndcg, _map, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
