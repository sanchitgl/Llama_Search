{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "dataset = \"msmarco_tiny\"\n",
    "\n",
    "dataset_path = \"../beir/datasets/msmarco_tiny/\"\n",
    "corpus_file = \"tiny_collection.json\"\n",
    "queries_file = \"topics.dl20.txt\"\n",
    "qrels_test_file = \"qrels.dl20-passage.txt\"\n",
    "training_set = \"msmarco_triples.train.tiny.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import losses, models, SentenceTransformer\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.train import TrainRetriever\n",
    "import pathlib, os, tqdm\n",
    "import logging\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"../beir/datasets/{dataset}\"\n",
    "# corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pytrec_eval\n",
    "import json\n",
    "\n",
    "def load_triplets(path):\n",
    "    triplets = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query, positive_passage, negative_passage = line.strip().split('\\t')\n",
    "            triplets.append([query, positive_passage, negative_passage])\n",
    "    return triplets\n",
    "\n",
    "def load_corpus_json(path):\n",
    "    with open(path, 'r') as corpus_f:\n",
    "        corpus_json = json.load(corpus_f)\n",
    "    return corpus_json\n",
    "\n",
    "\n",
    "triplets_temp = load_triplets(f\"{dataset_path}{training_set}\")\n",
    "corpus = load_corpus_json(f\"{dataset_path}{corpus_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:06:55 - Activating Elasticsearch....\n",
      "2024-06-02 16:06:55 - Elastic Search Credentials: {'hostname': 'localhost', 'index_name': 'msmarco_tiny', 'keys': {'title': 'title', 'body': 'txt'}, 'timeout': 100, 'retry_on_timeout': True, 'maxsize': 24, 'number_of_shards': 1, 'language': 'english'}\n",
      "2024-06-02 16:06:55 - Deleting previous Elasticsearch-Index named - msmarco_tiny\n",
      "2024-06-02 16:06:58 - Creating fresh Elasticsearch-Index named - msmarco_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/510585 [00:00<?, ?docs/s]                \n"
     ]
    }
   ],
   "source": [
    "#### Lexical Retrieval using Bm25 (Elasticsearch) ####\n",
    "\n",
    "## elasticsearch settings\n",
    "hostname = \"localhost\" #localhost\n",
    "index_name = dataset # scifact\n",
    "initialize = True # True - Delete existing index and re-index all documents from scratch \n",
    "\n",
    "number_of_shards = 1\n",
    "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize, number_of_shards=number_of_shards)\n",
    "bm25 = EvaluateRetrieval(model)\n",
    "\n",
    "#### Index passages into the index (seperately)\n",
    "bm25.retriever.index(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieve Hard Negatives using BM25: 100%|██████████| 11000/11000 [03:54<00:00, 46.86it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "triplets = []\n",
    "hard_negatives_max = 10\n",
    "\n",
    "#### Retrieve BM25 hard negatives => Given a positive document, find most similar lexical documents\n",
    "for query_text, pos_doc_text, neg_doc_text in tqdm.tqdm(triplets_temp, desc=\"Retrieve Hard Negatives using BM25\"):\n",
    "    hits = bm25.retriever.es.lexical_multisearch(texts=[pos_doc_text], top_hits=hard_negatives_max+1)\n",
    "    for (neg_id, _) in hits[0].get(\"hits\"):\n",
    "        if corpus[neg_id][\"text\"] != neg_doc_text:\n",
    "            neg_text = corpus[neg_id][\"text\"]\n",
    "            triplets.append([query_text, pos_doc_text, neg_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{dataset_path}{dataset}bm25_triplets.pickle\", 'wb') as f:\n",
    "            pickle.dump(triplets, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{dataset_path}{dataset}bm25_triplets.pickle\", 'rb') as f:\n",
    "    triplets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is a little caffeine ok during pregnancy',\n",
       " 'We donâ\\x80\\x99t know a lot about the effects of caffeine during pregnancy on you and your baby. So itâ\\x80\\x99s best to limit the amount you get each day. If youâ\\x80\\x99re pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.',\n",
       " 'It is generally safe for pregnant women to eat chocolate because studies have shown to prove certain benefits of eating chocolate during pregnancy. However, pregnant women should ensure their caffeine intake is below 200 mg per day.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is a little caffeine ok during pregnancy',\n",
       " 'We donâ\\x80\\x99t know a lot about the effects of caffeine during pregnancy on you and your baby. So itâ\\x80\\x99s best to limit the amount you get each day. If youâ\\x80\\x99re pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.',\n",
       " 'Should I limit caffeine during pregnancy? If youâ\\x80\\x99re pregnant, you should limit the amount of caffeine you have to 200 milligrams (mg) a day â\\x80\\x93 the equivalent of two mugs of instant coffee. Caffeine is found naturally in lots of foods, such as coffee, tea and chocolate.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is a little caffeine ok during pregnancy',\n",
       " 'We donâ\\x80\\x99t know a lot about the effects of caffeine during pregnancy on you and your baby. So itâ\\x80\\x99s best to limit the amount you get each day. If youâ\\x80\\x99re pregnant, limit caffeine to 200 milligrams each day. This is about the amount in 1Â½ 8-ounce cups of coffee or one 12-ounce cup of coffee.',\n",
       " 'Limit the amount of caffeine you get each day to 200 mg during pregnancy. Drinks and foods with caffeine incldue coffee, tea, energy drinks, soft drinks and chocolate. Limit the amount of caffeine you get each day to 200 mg during pregnancy.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:20:38 - Use pytorch device_name: cuda\n"
     ]
    }
   ],
   "source": [
    "#### Provide any sentence-transformers or HF model\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "#### Provide a high batch-size to train better with triplets!\n",
    "retriever = TrainRetriever(model=model, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Input Examples: 100%|██████████| 10081/10081 [00:00<00:00, 170816.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:20:41 - Loaded 120965 training pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### Prepare triplets samples\n",
    "train_samples = retriever.load_train_triplets(triplets=triplets)\n",
    "train_dataloader = retriever.prepare_train_triplets(train_samples)\n",
    "\n",
    "#### Training SBERT with cosine-product\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=retriever.model)\n",
    "\n",
    "#### Prepare dev evaluator\n",
    "# ir_evaluator = retriever.load_ir_evaluator(dev_corpus, dev_queries, dev_qrels)\n",
    "\n",
    "#### If no dev set is present from above use dummy evaluator\n",
    "ir_evaluator = retriever.load_dummy_evaluator()\n",
    "\n",
    "#### Provide model save path\n",
    "model_save_path = os.path.join(os.getcwd(), \"../output\", \"{}-v2-{}-bm25-hard-negs\".format(model_name, dataset))\n",
    "os.makedirs(model_save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:20:42 - Starting to Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100800' max='100800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100800/100800 2:58:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717370986.346945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717371535.171653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10080</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717371545.809072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717372080.916198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717372631.116839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20160</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717372651.581016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717373189.319853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717373748.967721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30240</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717373778.751595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717374304.727505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717374848.464861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40320</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717374885.836471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717375395.809792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717375952.925213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50400</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717375999.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717376506.386726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717377058.921684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60480</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717377114.743638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717377621.214825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717378166.056913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70560</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717378223.364392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717378666.603102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717379144.710644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80640</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717379209.302075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717379621.143968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717380108.860069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90720</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717380180.333874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717380596.713508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717381073.660550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100800</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717381154.364483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:29:46 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:38:55 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:39:05 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:48:00 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:57:11 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:57:31 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:06:29 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:15:48 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:16:18 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:25:04 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:34:08 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:34:45 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:43:15 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:52:32 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 17:53:19 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:01:46 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:10:58 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:11:54 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:20:21 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:29:26 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:30:23 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:37:46 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:45:44 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:46:49 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 18:53:41 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:01:48 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:03:00 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:09:56 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:17:53 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:19:14 - Save model to /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "#### Configure Train params\n",
    "num_epochs = 10\n",
    "evaluation_steps = 5000\n",
    "warmup_steps = int(len(train_samples) * num_epochs / retriever.batch_size * 0.1)\n",
    "\n",
    "retriever.fit(train_objectives=[(train_dataloader, train_loss)], \n",
    "                evaluator=ir_evaluator, \n",
    "                epochs=num_epochs,\n",
    "                output_path=model_save_path,\n",
    "                warmup_steps=warmup_steps,\n",
    "                evaluation_steps=evaluation_steps,\n",
    "                use_amp=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test set\n",
    "# corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")\n",
    "\n",
    "import collections\n",
    "import pytrec_eval\n",
    "import json\n",
    "\n",
    "def load_queries(path):\n",
    "    \"\"\"Returns a dictionary whose keys are query ids and values are query texts.\"\"\"\n",
    "    queries = {}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            query_id, query_text = line.strip().split('\\t')\n",
    "            queries[query_id] = query_text\n",
    "    return queries\n",
    "\n",
    "\n",
    "def load_qrels(path):\n",
    "    with open(path, 'r') as f_qrel:\n",
    "        qrels = pytrec_eval.parse_qrel(f_qrel)\n",
    "\n",
    "    return qrels\n",
    "\n",
    "\n",
    "def load_corpus_json(path):\n",
    "    with open(path, 'r') as corpus_f:\n",
    "        corpus_json = json.load(corpus_f)\n",
    "    return corpus_json\n",
    "\n",
    "\n",
    "qrels = load_qrels(f\"{dataset_path}{qrels_test_file}\")\n",
    "queries = load_queries(f\"{dataset_path}{queries_file}\")\n",
    "corpus = load_corpus_json(f\"{dataset_path}{corpus_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:38:42 - Loading faiss with AVX2 support.\n",
      "2024-06-02 19:38:42 - Successfully loaded faiss with AVX2 support.\n",
      "2024-06-02 19:38:42 - Use pytorch device_name: cuda\n",
      "2024-06-02 19:38:42 - Load pretrained SentenceTransformer: /data/addullah/253_proj/slm4search/src/../output/distilbert-base-uncased-v2-msmarco_tiny-bm25-hard-negs\n",
      "2024-06-02 19:38:43 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:38:43 - Sorting Corpus by document length (Longest first)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:38:43 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-06-02 19:38:43 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-06-02 19:38:43 - Encoding Batch 1/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [01:03<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:39:48 - Encoding Batch 2/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:40:41 - Encoding Batch 3/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:46<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:41:28 - Encoding Batch 4/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:37<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:42:06 - Encoding Batch 5/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:33<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:42:40 - Encoding Batch 6/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:31<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:43:12 - Encoding Batch 7/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:30<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:43:43 - Encoding Batch 8/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:28<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:44:12 - Encoding Batch 9/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:26<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:44:39 - Encoding Batch 10/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [00:23<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:45:03 - Encoding Batch 11/11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 83/83 [00:03<00:00, 22.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "## Load retriever from saved model\n",
    "\n",
    "model = DRES(models.SentenceBERT(model_save_path), batch_size=128)\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{dataset_path}{dataset}_distilBertBM_scores.pickle\", 'wb') as f:\n",
    "    pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 20:07:23 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-06-02 20:07:23 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2024-06-02 20:07:23 - \n",
      "\n",
      "2024-06-02 20:07:23 - NDCG@1: 0.5803\n",
      "2024-06-02 20:07:23 - NDCG@3: 0.5167\n",
      "2024-06-02 20:07:23 - NDCG@5: 0.5176\n",
      "2024-06-02 20:07:23 - NDCG@10: 0.4875\n",
      "2024-06-02 20:07:23 - NDCG@100: 0.4226\n",
      "2024-06-02 20:07:23 - NDCG@1000: 0.4880\n",
      "2024-06-02 20:07:23 - \n",
      "\n",
      "2024-06-02 20:07:23 - MAP@1: 0.0302\n",
      "2024-06-02 20:07:23 - MAP@3: 0.0688\n",
      "2024-06-02 20:07:23 - MAP@5: 0.0930\n",
      "2024-06-02 20:07:23 - MAP@10: 0.1331\n",
      "2024-06-02 20:07:23 - MAP@100: 0.2299\n",
      "2024-06-02 20:07:23 - MAP@1000: 0.2506\n",
      "2024-06-02 20:07:23 - \n",
      "\n",
      "2024-06-02 20:07:23 - Recall@1: 0.0302\n",
      "2024-06-02 20:07:23 - Recall@3: 0.0721\n",
      "2024-06-02 20:07:23 - Recall@5: 0.1036\n",
      "2024-06-02 20:07:23 - Recall@10: 0.1567\n",
      "2024-06-02 20:07:23 - Recall@100: 0.3703\n",
      "2024-06-02 20:07:23 - Recall@1000: 0.5426\n",
      "2024-06-02 20:07:23 - \n",
      "\n",
      "2024-06-02 20:07:23 - P@1: 0.7037\n",
      "2024-06-02 20:07:23 - P@3: 0.6482\n",
      "2024-06-02 20:07:23 - P@5: 0.6296\n",
      "2024-06-02 20:07:23 - P@10: 0.5389\n",
      "2024-06-02 20:07:23 - P@100: 0.1813\n",
      "2024-06-02 20:07:23 - P@1000: 0.0300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.58025,\n",
       "  'NDCG@3': 0.51669,\n",
       "  'NDCG@5': 0.51756,\n",
       "  'NDCG@10': 0.4875,\n",
       "  'NDCG@100': 0.4226,\n",
       "  'NDCG@1000': 0.48799},\n",
       " {'MAP@1': 0.03016,\n",
       "  'MAP@3': 0.0688,\n",
       "  'MAP@5': 0.09296,\n",
       "  'MAP@10': 0.13311,\n",
       "  'MAP@100': 0.22992,\n",
       "  'MAP@1000': 0.25063},\n",
       " {'Recall@1': 0.03016,\n",
       "  'Recall@3': 0.0721,\n",
       "  'Recall@5': 0.10357,\n",
       "  'Recall@10': 0.15667,\n",
       "  'Recall@100': 0.37034,\n",
       "  'Recall@1000': 0.54264},\n",
       " {'P@1': 0.7037,\n",
       "  'P@3': 0.64815,\n",
       "  'P@5': 0.62963,\n",
       "  'P@10': 0.53889,\n",
       "  'P@100': 0.1813,\n",
       "  'P@1000': 0.02998})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "ndcg, _map, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
