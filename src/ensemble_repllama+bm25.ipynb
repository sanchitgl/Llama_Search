{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "dataset = \"msmarco_tiny\"\n",
    "\n",
    "dataset_path = \"../beir/datasets/msmarco_tiny/\"\n",
    "corpus_file = \"tiny_collection.json\"\n",
    "queries_file = \"topics.dl20.txt\"\n",
    "qrels_test_file = \"qrels.dl20-passage.txt\"\n",
    "training_set = \"msmarco_triples.train.tiny.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import losses, models, SentenceTransformer\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.train import TrainRetriever\n",
    "import pathlib, os, tqdm\n",
    "import logging\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [11:06<00:00, 12.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load repLlama scores\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "with open(f\"{dataset_path}tiny_collection_llamaEmbed.pickle\", 'rb') as f:\n",
    "    doc_embeddings = pickle.load(f)\n",
    "\n",
    "with open(f\"{dataset_path}queries_llamaEmbed.pickle\", 'rb') as f:\n",
    "    query_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "results_dense = {}\n",
    "for q_id, q_embed in tqdm(query_embeddings.items()):\n",
    "    results_dense[q_id] = {}\n",
    "    for d_id, d_embed in doc_embeddings.items():\n",
    "        # compute similarity score\n",
    "        score = torch.dot(q_embed, d_embed)\n",
    "        results_dense[q_id][d_id] = score.item() #.item() to get value out of tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{dataset_path}{dataset}_repLlama_scores.pickle\", 'wb') as f:\n",
    "#     pickle.dump(results_dense, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"{dataset_path}{dataset}_repLlama_scores.pickle\", 'rb') as f:\n",
    "    results_dense = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BM25 scores\n",
    "import pickle \n",
    "\n",
    "with open(f\"{dataset_path}{dataset}_bm25_scores.pickle\", 'rb') as f:\n",
    "    results_bm25 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5468878746032715, 0.9585447907447815, 4.215731, 49.542587)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_maxmin(results):\n",
    "    max_score = -1\n",
    "    min_score = 999999\n",
    "    for q_id, q in results.items():\n",
    "        for doc_id, score in q.items():\n",
    "            max_score = max(score, max_score)\n",
    "            min_score = min(score, min_score)\n",
    "\n",
    "    return min_score, max_score\n",
    "\n",
    "# Get range to normalize both\n",
    "min_distilbert_score, max_distilbert_score = get_maxmin(results_dense)\n",
    "min_bm25_score, max_bm25_score = get_maxmin(results_bm25)\n",
    "\n",
    "min_distilbert_score, max_distilbert_score, min_bm25_score, max_bm25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "def normalize_results(results, min_score, max_score):\n",
    "    for q_id, q in results.items():\n",
    "        for doc_id, score in q.items():\n",
    "            results[q_id][doc_id] = (score-min_score)/(max_score-min_score)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = normalize_results(results_dense, min_distilbert_score, max_distilbert_score)\n",
    "results_bm25 = normalize_results(results_bm25, min_bm25_score, max_bm25_score)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_score(x,y):\n",
    "    mu = 0.8\n",
    "    return mu*x + (1-mu)*y\n",
    "\n",
    "combined_result = {}\n",
    "\n",
    "for q_id_1, q_1 in results.items():\n",
    "        combined_result[q_id_1] = {}\n",
    "        for doc_id_1, score_1 in q_1.items():\n",
    "            \n",
    "            score_2 = 0\n",
    "            if results_bm25[q_id_1].get(doc_id_1,None)!=None:\n",
    "                score_2 = results_bm25[q_id_1][doc_id_1]\n",
    "                del results_bm25[q_id_1][doc_id_1] # So that same query-doc pair is not added to combined result twice\n",
    "            \n",
    "            combined_score = ensemble_score(score_1, score_2)\n",
    "            combined_result[q_id_1][doc_id_1] = combined_score\n",
    "\n",
    "\n",
    "# Now add remaining bm25 results in combined dict\n",
    "for q_id_2, q_2 in results_bm25.items():\n",
    "    for doc_id_2, score_2 in q_2.items():\n",
    "         score_1 = 0\n",
    "         combined_score = ensemble_score(score_1, score_2)\n",
    "         combined_result[q_id_1][doc_id_1] = combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 21:50:17 - Activating Elasticsearch....\n",
      "2024-06-02 21:50:17 - Elastic Search Credentials: {'hostname': 'localhost', 'index_name': 'msmarco_tiny_1', 'keys': {'title': 'title', 'body': 'txt'}, 'timeout': 100, 'retry_on_timeout': True, 'maxsize': 24, 'number_of_shards': 'default', 'language': 'english'}\n",
      "2024-06-02 21:50:17 - Deleting previous Elasticsearch-Index named - msmarco_tiny_1\n",
      "2024-06-02 21:50:17 - Unable to create Index in Elastic Search. Reason: ConnectionError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fg\\x00 identity\\r\\n'))) caused by: ProtocolError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fg\\x00 identity\\r\\n')))\n",
      "2024-06-02 21:50:19 - Creating fresh Elasticsearch-Index named - msmarco_tiny_1\n",
      "2024-06-02 21:50:19 - Unable to create Index in Elastic Search. Reason: ConnectionError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fn\\x00ent-Length: 117\\r\\n'))) caused by: ProtocolError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fn\\x00ent-Length: 117\\r\\n')))\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "## elasticsearch settings\n",
    "hostname = \"localhost\" #localhost\n",
    "index_name = dataset+'_1' # scifact\n",
    "initialize = True # True - Delete existing index and re-index all documents from scratch \n",
    "\n",
    "model_bm25 = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
    "retriever_bm25 = EvaluateRetrieval(model_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pytrec_eval\n",
    "import json\n",
    "\n",
    "def load_qrels(path):\n",
    "    with open(path, 'r') as f_qrel:\n",
    "        qrels = pytrec_eval.parse_qrel(f_qrel)\n",
    "\n",
    "    return qrels\n",
    "\n",
    "qrels = load_qrels(f\"{dataset_path}{qrels_test_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-02 21:54:09 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2024-06-02 21:54:31 - \n",
      "\n",
      "2024-06-02 21:54:31 - NDCG@1: 0.7623\n",
      "2024-06-02 21:54:31 - NDCG@3: 0.7373\n",
      "2024-06-02 21:54:31 - NDCG@5: 0.7066\n",
      "2024-06-02 21:54:31 - NDCG@10: 0.6922\n",
      "2024-06-02 21:54:31 - NDCG@100: 0.7147\n",
      "2024-06-02 21:54:31 - NDCG@1000: 0.8100\n",
      "2024-06-02 21:54:31 - \n",
      "\n",
      "2024-06-02 21:54:31 - MAP@1: 0.0396\n",
      "2024-06-02 21:54:31 - MAP@3: 0.0864\n",
      "2024-06-02 21:54:31 - MAP@5: 0.1211\n",
      "2024-06-02 21:54:31 - MAP@10: 0.2026\n",
      "2024-06-02 21:54:31 - MAP@100: 0.5245\n",
      "2024-06-02 21:54:31 - MAP@1000: 0.6027\n",
      "2024-06-02 21:54:31 - \n",
      "\n",
      "2024-06-02 21:54:31 - Recall@1: 0.0396\n",
      "2024-06-02 21:54:31 - Recall@3: 0.0872\n",
      "2024-06-02 21:54:31 - Recall@5: 0.1255\n",
      "2024-06-02 21:54:31 - Recall@10: 0.2351\n",
      "2024-06-02 21:54:31 - Recall@100: 0.7199\n",
      "2024-06-02 21:54:31 - Recall@1000: 0.9492\n",
      "2024-06-02 21:54:31 - \n",
      "\n",
      "2024-06-02 21:54:31 - P@1: 0.8889\n",
      "2024-06-02 21:54:31 - P@3: 0.8395\n",
      "2024-06-02 21:54:31 - P@5: 0.7852\n",
      "2024-06-02 21:54:31 - P@10: 0.7389\n",
      "2024-06-02 21:54:31 - P@100: 0.3854\n",
      "2024-06-02 21:54:31 - P@1000: 0.0620\n"
     ]
    }
   ],
   "source": [
    "ndcg, _map, recall, precision = retriever_bm25.evaluate(qrels, combined_result, retriever_bm25.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
