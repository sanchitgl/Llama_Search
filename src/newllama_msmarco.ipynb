{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qB3FjHNhxOpq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/addullah/miniconda3/envs/myenv/lib/python3.12/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pkWHYBDgxOsZ"
      },
      "outputs": [],
      "source": [
        "logging.set_verbosity_info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ACKrrHzIxOu_"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "new_model = \"llama-2-7b-IR2\"\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 16\n",
        "per_device_eval_batch_size = 16\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 0\n",
        "logging_steps = 25\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RymaCUm4Z3ID"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from peft import PeftModel, PeftConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "f5b490a6cbec42d198039ff9413c6f59",
            "4a060d9601c141f8bde29eea8d997a45",
            "dca800618dc542c0b7146b6dc13c64bc",
            "3dfedf26e6914f42a1252e8aaa9694f5",
            "572c020938964904a5ecdbf2ffedd7e0",
            "30af597bb89d410799052e1ee8dc347c",
            "38d1b528fafc479d8957983fe93e57f4",
            "a487447a95b34006ac96865d19e6e651",
            "c84b512a73b948a9b7c07e05874067b0",
            "842d0dbfbcfe4cf7a8a442afe3f7081c",
            "4c1727dccb4f4d48837b5d4d1ce88e52"
          ]
        },
        "id": "xerNIDaZZhyw",
        "outputId": "7f18a88d-c080-431d-f847-6216e958cd1d"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from peft import PeftModel\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# def get_model(peft_model_name):\n",
        "#     config = PeftConfig.from_pretrained(peft_model_name)\n",
        "#     base_model = AutoModel.from_pretrained(config.base_model_name_or_path, device_map={\"\": 0})\n",
        "#     model = PeftModel.from_pretrained(base_model, peft_model_name)\n",
        "#     model = model.merge_and_unload()\n",
        "#     model.eval()\n",
        "#     return model\n",
        "\n",
        "# # Load the tokenizer and model\n",
        "# tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-chat-hf')\n",
        "# model = get_model(\"../models/Llama_new\")\n",
        "\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlcfGhGX5Hvo",
        "outputId": "dfcaf8b0-99d0-4994-d86b-b2d6b9afb4eb"
      },
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSLRFLPh0i-r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I7LWh0uYxomL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from beir import util, LoggingHandler\n",
        "from beir.retrieval import models\n",
        "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "import logging\n",
        "import collections\n",
        "import pytrec_eval\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    level=logging.INFO,\n",
        "    handlers=[LoggingHandler()]\n",
        ")\n",
        "\n",
        "# Define file paths\n",
        "corpus_file = \"tiny_collection.json\"\n",
        "queries_file = \"topics.dl20.txt\"\n",
        "qrels_test_file = \"qrels.dl20-passage.txt\"\n",
        "dataset_path = \"../beir/datasets/msmarco_tiny/\"\n",
        "\n",
        "# Load queries\n",
        "def load_queries(path):\n",
        "    queries = {}\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            query_id, query_text = line.strip().split('\\t')\n",
        "            queries[query_id] = query_text\n",
        "    return queries\n",
        "\n",
        "# Load qrels\n",
        "def load_qrels(path):\n",
        "    with open(path, 'r') as f_qrel:\n",
        "        qrels = pytrec_eval.parse_qrel(f_qrel)\n",
        "    return qrels\n",
        "\n",
        "# Load corpus\n",
        "def load_corpus_json(path):\n",
        "    with open(path, 'r') as corpus_f:\n",
        "        corpus_json = json.load(corpus_f)\n",
        "    return corpus_json\n",
        "\n",
        "qrels = load_qrels(os.path.join(dataset_path, qrels_test_file))\n",
        "queries = load_queries(os.path.join(dataset_path, queries_file))\n",
        "corpus = load_corpus_json(os.path.join(dataset_path, corpus_file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSdhaegUcBjH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERJCnzyT32Aq"
      },
      "outputs": [],
      "source": [
        "# def get_embed_dataset(input_lst):\n",
        "\n",
        "#     input_txt = [f'{input}</s>' for input in input_lst['text']]\n",
        "\n",
        "#     tokenized_inputs = tokenizer(input_txt, return_tensors='pt', padding=\"max_length\", truncation=True, max_length=tokenizer_max_len)\n",
        "#     tokenized_inputs = tokenized_inputs.to(device)\n",
        "#     with torch.no_grad():\n",
        "#         # compute query embedding\n",
        "#         outputs = model(**tokenized_inputs)\n",
        "#         embedding = outputs.last_hidden_state[:,-1,:]   #outputs.last_hidden_state[0][-1] # Get embedding of last token i.e. <s>\n",
        "#         embedding = torch.nn.functional.normalize(embedding, p=2, dim=0)\n",
        "#     return embedding\n",
        "\n",
        "# def get_embed(input):\n",
        "\n",
        "#     tokenized_inputs = tokenizer(f'{input}</s>', return_tensors='pt')\n",
        "#     tokenized_inputs = tokenized_inputs.to(device)\n",
        "#     with torch.no_grad():\n",
        "#         # compute query embedding\n",
        "#         outputs = model(**tokenized_inputs)\n",
        "#         embedding = outputs.last_hidden_state[0][-1] #outputs.last_hidden_state[:,-1,:]  # Get embedding of last token i.e. </s>\n",
        "#         embedding = torch.nn.functional.normalize(embedding, p=2, dim=0)\n",
        "#     return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oGoRskh20rN",
        "outputId": "16482069-3db0-42ca-8a81-3ef37bfedd1d"
      },
      "outputs": [],
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# query_embeddings = {}\n",
        "# doc_embeddings = {}\n",
        "\n",
        "# print(\"Encoding queries ...\")\n",
        "# for k,q in tqdm(queries.items()):\n",
        "#     query_embed = get_embed(q)\n",
        "#     query_embeddings[k] = query_embed\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# # Can't save tensors to json\n",
        "# with open(f\"{dataset_path}queries_newllamaEmbed.pickle\", 'wb') as f:\n",
        "#     pickle.dump(query_embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# print(\"Encoding passages ...\")\n",
        "# i = 0\n",
        "# for k,q in tqdm(corpus.items()):\n",
        "#     i+=1\n",
        "#     doc_embed = get_embed(q['text'])\n",
        "#     doc_embeddings[k] = doc_embed\n",
        "\n",
        "#     if i%50_000==0:\n",
        "#         with open(f\"{dataset_path}corpus_newllamaEmbed_{i}.pickle\", 'wb') as f:\n",
        "#             pickle.dump(doc_embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# with open(f\"{dataset_path}corpus_newllamaEmbed.pickle\", 'wb') as f:\n",
        "#     pickle.dump(doc_embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{dataset_path}corpus_newllamaEmbed.pickle\", 'rb') as f:\n",
        "    doc_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(f\"{dataset_path}queries_newllamaEmbed.pickle\", 'rb') as f:\n",
        "    query_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [10:07<00:00, 11.26s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "results = {}\n",
        "for q_id, q_embed in tqdm(query_embeddings.items()):\n",
        "    results[q_id] = {}\n",
        "    for d_id, d_embed in doc_embeddings.items():\n",
        "        # compute similarity score\n",
        "        score = torch.dot(q_embed, d_embed)\n",
        "        results[q_id][d_id] = score.item() #.item() to get value out of tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nDCG@10: 0.0283\n"
          ]
        }
      ],
      "source": [
        "import pytrec_eval\n",
        "\n",
        "metric = 'ndcg_cut_10'\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {metric})\n",
        "results_metric = evaluator.evaluate(results)\n",
        "print(f'nDCG@10: {sum(item[metric] for item in results_metric.values()) / len(results_metric):0.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-02 08:22:47 - Activating Elasticsearch....\n",
            "2024-06-02 08:22:47 - Elastic Search Credentials: {'hostname': 'localhost', 'index_name': 'msmarco_abd', 'keys': {'title': 'title', 'body': 'txt'}, 'timeout': 100, 'retry_on_timeout': True, 'maxsize': 24, 'number_of_shards': 'default', 'language': 'english'}\n",
            "2024-06-02 08:22:47 - Deleting previous Elasticsearch-Index named - msmarco_abd\n",
            "2024-06-02 08:22:47 - Unable to create Index in Elastic Search. Reason: ConnectionError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fi\\x00entity\\r\\n'))) caused by: ProtocolError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fi\\x00entity\\r\\n')))\n",
            "2024-06-02 08:22:49 - Creating fresh Elasticsearch-Index named - msmarco_abd\n",
            "2024-06-02 08:22:49 - Unable to create Index in Elastic Search. Reason: ConnectionError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fn\\x00-Length: 117\\r\\n'))) caused by: ProtocolError(('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fn\\x00-Length: 117\\r\\n')))\n",
            "2024-06-02 08:22:49 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
            "2024-06-02 08:23:10 - \n",
            "\n",
            "2024-06-02 08:23:10 - NDCG@1: 0.0185\n",
            "2024-06-02 08:23:10 - NDCG@3: 0.0307\n",
            "2024-06-02 08:23:10 - NDCG@5: 0.0285\n",
            "2024-06-02 08:23:10 - NDCG@10: 0.0283\n",
            "2024-06-02 08:23:10 - NDCG@100: 0.0386\n",
            "2024-06-02 08:23:10 - NDCG@1000: 0.0687\n",
            "2024-06-02 08:23:10 - \n",
            "\n",
            "2024-06-02 08:23:10 - MAP@1: 0.0009\n",
            "2024-06-02 08:23:10 - MAP@3: 0.0029\n",
            "2024-06-02 08:23:10 - MAP@5: 0.0031\n",
            "2024-06-02 08:23:10 - MAP@10: 0.0039\n",
            "2024-06-02 08:23:10 - MAP@100: 0.0065\n",
            "2024-06-02 08:23:10 - MAP@1000: 0.0083\n",
            "2024-06-02 08:23:10 - \n",
            "\n",
            "2024-06-02 08:23:10 - Recall@1: 0.0009\n",
            "2024-06-02 08:23:10 - Recall@3: 0.0042\n",
            "2024-06-02 08:23:10 - Recall@5: 0.0050\n",
            "2024-06-02 08:23:10 - Recall@10: 0.0089\n",
            "2024-06-02 08:23:10 - Recall@100: 0.0389\n",
            "2024-06-02 08:23:10 - Recall@1000: 0.1244\n",
            "2024-06-02 08:23:10 - \n",
            "\n",
            "2024-06-02 08:23:10 - P@1: 0.0185\n",
            "2024-06-02 08:23:10 - P@3: 0.0556\n",
            "2024-06-02 08:23:10 - P@5: 0.0444\n",
            "2024-06-02 08:23:10 - P@10: 0.0370\n",
            "2024-06-02 08:23:10 - P@100: 0.0224\n",
            "2024-06-02 08:23:10 - P@1000: 0.0070\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "({'NDCG@1': 0.01852,\n",
              "  'NDCG@3': 0.03071,\n",
              "  'NDCG@5': 0.02854,\n",
              "  'NDCG@10': 0.02833,\n",
              "  'NDCG@100': 0.03862,\n",
              "  'NDCG@1000': 0.06866},\n",
              " {'MAP@1': 0.00088,\n",
              "  'MAP@3': 0.00293,\n",
              "  'MAP@5': 0.00313,\n",
              "  'MAP@10': 0.00392,\n",
              "  'MAP@100': 0.00652,\n",
              "  'MAP@1000': 0.00828},\n",
              " {'Recall@1': 0.00088,\n",
              "  'Recall@3': 0.00421,\n",
              "  'Recall@5': 0.00499,\n",
              "  'Recall@10': 0.00886,\n",
              "  'Recall@100': 0.03895,\n",
              "  'Recall@1000': 0.12443},\n",
              " {'P@1': 0.01852,\n",
              "  'P@3': 0.05556,\n",
              "  'P@5': 0.04444,\n",
              "  'P@10': 0.03704,\n",
              "  'P@100': 0.02241,\n",
              "  'P@1000': 0.00696})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from beir.retrieval.search.lexical import BM25Search as BM25\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "\n",
        "hostname = \"localhost\"\n",
        "index_name = \"msmarco_abd\"\n",
        "initialize = True\n",
        "\n",
        "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
        "retriever = EvaluateRetrieval(model)\n",
        "# model doesn't do anything and results for ndcg and map are same as pytrec_eval\n",
        "\n",
        "retriever.evaluate(qrels, results, retriever.k_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30af597bb89d410799052e1ee8dc347c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d1b528fafc479d8957983fe93e57f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dfedf26e6914f42a1252e8aaa9694f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842d0dbfbcfe4cf7a8a442afe3f7081c",
            "placeholder": "​",
            "style": "IPY_MODEL_4c1727dccb4f4d48837b5d4d1ce88e52",
            "value": " 2/2 [00:58&lt;00:00, 26.64s/it]"
          }
        },
        "4a060d9601c141f8bde29eea8d997a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30af597bb89d410799052e1ee8dc347c",
            "placeholder": "​",
            "style": "IPY_MODEL_38d1b528fafc479d8957983fe93e57f4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4c1727dccb4f4d48837b5d4d1ce88e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572c020938964904a5ecdbf2ffedd7e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842d0dbfbcfe4cf7a8a442afe3f7081c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a487447a95b34006ac96865d19e6e651": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84b512a73b948a9b7c07e05874067b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dca800618dc542c0b7146b6dc13c64bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a487447a95b34006ac96865d19e6e651",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c84b512a73b948a9b7c07e05874067b0",
            "value": 2
          }
        },
        "f5b490a6cbec42d198039ff9413c6f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a060d9601c141f8bde29eea8d997a45",
              "IPY_MODEL_dca800618dc542c0b7146b6dc13c64bc",
              "IPY_MODEL_3dfedf26e6914f42a1252e8aaa9694f5"
            ],
            "layout": "IPY_MODEL_572c020938964904a5ecdbf2ffedd7e0"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
